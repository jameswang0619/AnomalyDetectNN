# -*- coding: utf-8 -*-
"""NNratio_1D.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/13zC6nTSvjEFa_-FFy6-Rpy5zH8bUUlMJ
"""

from __future__ import print_function
from __future__ import division
import keras
import os
from keras.models import Sequential
from keras import layers
from keras import backend as K
from keras.layers import Activation, Dense
from keras.constraints import Constraint
from keras.constraints import max_norm

from math import *
import numpy as np
#import matplotlib.pyplot as plt
#from mpl_toolkits.mplot3d import Axes3D
import scipy.integrate as integrate
import scipy.stats as st
import time



#sigmoid function
def sigmoid(x):
  return 1 / (1 + exp(-x))

#@title Glabal Parameters
epochs = 100000 #@param {type:"integer"}
batch_size = 1000 #@param {type:"integer"}
Geteps = 0.0009 #@param {type:"number"}
Getmu = 0.8 #@param {type:"number"}
Getsigma = 0.02 #@param {type:"number"}
cut = 0. #@param {type:"number"}
gcut = 0. #@param {type:"number"}

def SM(x):
  return exp(-8*x)

def BSM(x):
  return exp(-(x-Getmu)**2/(2*Getsigma**2))
#Normalize distribution
SM_norm = integrate.quad(lambda y :SM(y),cut,1)
BSM_norm = integrate.quad(lambda y :BSM(y),cut,1)
#SM_norm_c = integrate.quad(lambda y :SMn(y),gcut,1)

#normalized distribution
def SMn(x):
  return exp(-8*x)/SM_norm[0]

def BSMn(x):
  return (SMn(x)+Geteps*BSM(x)/BSM_norm[0])/(1+Geteps)

SM_norm_c = integrate.quad(lambda y :SM(y),gcut,1)

def SMnc(x):
  return exp(-8*x)/SM_norm_c[0]


#define probability distribution function
class P_SM(st.rv_continuous):
    def _pdf(self,x):
        return SMn(x)
      
class P_BSM(st.rv_continuous):
    def _pdf(self,x):
        return BSMn(x)        
      
class P_SMc(st.rv_continuous):
    def _pdf(self,x):
        return SMnc(x)
      
      
      
SM_gen = P_SM(a=cut,b=1,name='sm_sample')
BSM_gen = P_BSM(a=cut,b=1,name='bsm_sample')
SMc_gen = P_SMc(a=gcut,b=1,name='smc_sample')

def anglen(x):
  nm = integrate.quad(lambda y: 1*cos(y),-pi/2,pi/2)
  return (1*cos(x))/nm[0]

class P_angle(st.rv_continuous):
  def _pdf(self,x):
    return anglen(x)

angle_gen = P_angle(a=-pi/2,b=pi/2, name='angle')

NRef=200000
NR =20000
Nbsm=NR*(1+Geteps)

#load data
#samples = np.load('Sample200k_4k_2d.npz')
#Ref_sample=samples['Ref_sample']
#bsm_sample=samples['bsm_sample']
#Data and References
Nrbsm = np.random.poisson(Nbsm,1)[0]
Ref_sample = SM_gen.rvs(size=NRef)
bsm_sample= BSM_gen.rvs(size=Nrbsm)

angleSM = angle_gen.rvs(size=NRef)
angleBSM = angle_gen.rvs(size=Nrbsm)

sm_target = np.zeros(NRef)
#bsm_target = np.ones(Nbsm)

#x_train = np.append(Ref_sample,bsm_sample)
#y_train = np.append(sm_target,bsm_target)

rfw = NRef/NR

#sfilename = 'Sample200k_4k_2d'
#np.savez(sfilename,bsm_sample=bsm_sample,Ref_sample=Ref_sample,anglesSM=anglesSM,anglesBSM=anglesBSM)

"""## Binning the Ref sample"""

Nb_angle = 50
Nb_mass = 500

H2d,yedge,xedge = np.histogram2d(angleSM,Ref_sample,bins=[np.linspace(-pi/2,pi/2,Nb_angle+1),np.linspace(0,1,Nb_mass+1)])

def moving_average(a, n=2) :
    ret = np.cumsum(a, dtype=float)
    ret[n:] = ret[n:] - ret[:-n]
    return ret[n - 1:] / n


xpos = moving_average(xedge,2);

ypos = moving_average(yedge,2);

wlist = []

for xidx, xval in enumerate(xpos):
  for yidx, yval in enumerate(ypos):
    wlist.append([yval,xval,H2d[yidx][xidx]])

xposf=[]; yposf=[]; zposf=[];

for elem in wlist:
  xposf.append(elem[1])
  yposf.append(elem[0])
  zposf.append(elem[2])

Nbins = Nb_angle*Nb_mass
xmass = np.append(xposf,bsm_sample)
xangle = np.append(yposf,angleBSM)
#sm_target = np.zeros(NRsm)
sm_target = np.zeros(Nbins)
bsm_target = np.ones(Nrbsm)

#x_train = np.append(sm_sample,bsm_sample)
x_train = np.column_stack((xmass,xangle))
y_train = np.append(sm_target,bsm_target)
weightlossa = np.append(np.asarray(zposf),bsm_target)
weightloss = K.variable(value=weightlossa.reshape((Nrbsm+Nbins,1)))





"""## Build NN and Train"""



#define custom loss function

def customloss(yTrue,yPred):
  return yTrue*K.log(1+K.exp(-yPred))+1/rfw*(1-yTrue)*K.log(1+K.exp(yPred))


def customlossML(sw):
  Nt = Nrbsm+Nbins
  def lossML(yTrue,yPred):
    sw_rs = K.reshape(sw,(Nt,1))
    ytrue_rs = K.reshape(yTrue,(Nt,1))
    ypred_rs = K.reshape(yPred,(Nt,1))
    return -K.sum(ytrue_rs*sw_rs*ypred_rs)+K.sum((1-ytrue_rs)*sw_rs*(K.exp(ypred_rs)-1))/rfw
  return lossML

def customlossMLws(yTrue,yPred):
  return -yTrue*yPred+1/rfw*(1-yTrue)*(K.exp(yPred)-1)

rmsprop = keras.optimizers.RMSprop()

class WeightClip(Constraint):
    '''Clips the weights incident to each hidden unit to be inside a range
    '''
    def __init__(self, c=2):
        self.c = c

    def __call__(self, p):
        return K.clip(p, -self.c, self.c)

    def get_config(self):
        return {'name': self.__class__.__name__,
                'c': self.c}

# build the model
model = Sequential()
model.add(Dense(4, activation='sigmoid',input_shape=(2,),kernel_regularizer=keras.regularizers.l2(0.),W_constraint = WeightClip(40),b_constraint=WeightClip(40)))
#model.add(Dense(4, activation='sigmoid',input_shape=(1,),kernel_regularizer=keras.regularizers.l2(0.0),kernel_constraint=max_norm(10.),bias_constraint=max_norm(10.)))
#model.add(Dense(4, activation='sigmoid',input_shape=(1,),kernel_regularizer=keras.regularizers.l2(0.0001)))
#model.add(Dense(3, activation='sigmoid'))
#model.add(Dense(3, activation='sigmoid'))
model.add(Dense(1,W_constraint=WeightClip(40)))



# compile the model
#model.compile(loss=customlossML(weightloss), optimizer='rmsprop')

model.compile(loss=customlossML(weightloss), optimizer ='rmsprop')
model.save_weights("model_4_2d.h5")

'''
#Visualize network
#from keras.utils import plot_model
#plot_model(model,to_file='model.png',show_shapes='True')
from IPython.display import SVG
from keras.utils.vis_utils import model_to_dot

SVG(model_to_dot(model).create(prog='dot', format='svg'))
'''

#load weight and continue training
#import h5py

#sample1
#model.load_weights("modelML_9_cut5_D400_200_L2R0_MN0_sigmoid_2000k.h5")

#sample2
#model.load_weights("model_5_R2_R500k.h5")

'''
model.fit(x_train, y_train,
          batch_size=len(x_train),
          epochs=400000,
          shuffle=False,
          verbose=0)

filename = 'modelML_4_2d_D200k_4k_WC40_sigmoid_400k.h5'
model.save_weights(filename)
'''





"""### test statistics vs. Run"""

def t_vs_run(drun,ite):
    t_v_array=[]
    i=0;
    while i < ite:
      model.fit(x_train, y_train,
          batch_size=len(x_train),
          epochs=drun,
          shuffle=False,
          verbose=0);
      #tary = 2*(model.predict(np.column_stack((bsm_cut,anglesBSM_c)))).flatten();
      tary1 = 2*(model.predict(bsm_sample)).flatten();
      tary3 = 2*np.vectorize(exp)(model.predict(Ref_sample)).flatten();
      tary2 = -2*(model.evaluate(x=x_train,y=y_train,batch_size=len(x_train))).flatten();
      #tary3 = -2*(model.evaluate(x=bsm_sample,y=bsm_target,batch_size=len(bsm_sample))).flatten();
      t_v_array = np.append(t_v_array,np.array([np.sum(tary1),np.sum(tary2),np.sum(tary3)]));
      i +=1
    
    #model.save_weights("model1d_4.h5")
    return t_v_array

#R14
#t = time.process_time()
#ta = t_vs_run(100000,5)
#print(time.process_time() - t)

#distribution of t



class test_statistics:
  '''
  Compute test statistics given data sample(bsm or sm) 
  '''
  def __init__(self,NNmodel):
    #self.input_sample = input_sample
    #self.ref_sample = ref_sample
    self.NNmodel = NNmodel
    #self.lossfunc = lossfunc

  #train NN with data(input) sample and ref sample
  #training variables
  
  #generate sm sample

  def sample_t(self):
      sample20k = np.load('SM_and_BSM_samples_20k_poisson_1_500_R1.npy').item()
  
  def train_t(self,epoch):
      Ndata = np.random.poisson(NR,1)[0]
      self.data_sample_t = SMc_gen.rvs(size=Ndata)
      # self.data_sample_t = BSM_gen.rvs(size=Ndata)
      self.angle_sample_t = angle_gen.rvs(size=Ndata)
      self.H2d, self.yedge, self.xedge = np.histogram2d(self.angle_sample_t,
                                                        self.data_sample_t,
                                                        bins=[np.linspace(-pi/2,pi/2,Nb_angle+1),np.linspace(0,1,Nb_mass+1)])
      self.xpos = moving_average(self.xedge,2)
      self.ypos = moving_average(self.yedge,2)
      bsm_target_tc = np.ones(Nbins)
      self.wlist_d = []
      for xidx, xval in enumerate(xpos):
          for yidx, yval in enumerate(ypos):
              self.wlist_d.append([yval,xval,self.H2d[yidx][xidx]])

      self.xposf=[]; self.yposf=[]; self.zposf = [];
      for elem in wlist:
          self.xposf.append(elem[1])
          self.yposf.append(elem[0])
          self.zposf.append(elem[2])
      self.x_mass_t = np.append(xposf, self.xposf)
      self.x_angle_t = np.append(yposf, self.yposf) 
      self.x_train_t = np.column_stack((self.x_mass_t,self.x_angle_t))
      self.y_train_t = np.append(sm_target, bsm_target_tc) 
      self.weightlossa = np.append(np.asarray(self.zposf),bsm_target_tc)
      self.weightloss = K.variable(value=self.weightlossa.reshape((Nbins+Nbins,1)))
      self.NNmodel.compile(loss=customlossML(self.weightloss), optimizer=rmsprop)
      self.NNmodel.load_weights("model_4_2d.h5")
      self.NNmodel.fit(self.x_train_t, self.y_train_t,
                       batch_size=len(self.x_train_t),
                       epochs=epoch,
                       shuffle=False,
                       verbose=0)
      tary = -2*(model.evaluate(x=self.x_train_t,y=self.y_train_t,batch_size=len(self.x_train_t))).flatten();
      return (np.sum(tary))
    

    
    


"""# Save and Continue training"""

#load weight and continue training
#model.load_weights("model_5_3.h5")

#Save weight to HDF5
#model.save_weights("model2.h5")
#print("Save model to disk")

#sfilename = 't_value'
#Sample200k_4k.npz
#np.savez(sfilename,t_value=ta)
'''
model.fit(x_train, y_train,
          batch_size=len(x_train),
          epochs=15000,
          sample_weight=weightloss,
          verbose=0)
      #tary = 2*(model.predict(np.column_stack((bsm_cut,anglesBSM_c)))).flatten();
tary = 2*(model.predict(bsm_sample)).flatten()
#print(np.sum(tary))
'''
#model_weight=model.get_weights()
#smtrain1 = test_statistics(model,customlossMLc)
#ta=smtrain1.t_vs_run(10000,200)

def get_tsm(Nsample):
    tvalue_array = []
    smtrain = test_statistics(model)
    i=0
    while i < Nsample:
        tvalue_array.append(smtrain.train_t(300000))
        i += 1
    
    return tvalue_array

tarrayR1 = get_tsm(2)
#f = open('tsm_300k_eps9eN4_Rtest.txt','w')
with open('tsm_300k_eps9eN4_Rtest.txt','w') as f:
    f.write('{}'.format(tarrayR1))

#f.write('{}'.format(model_weight))
#f.write('{}'.format(ta))
#f.write('{}'.format(tarrayR1))
#f.close()

